{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "colab": {
      "name": "demo_i3d_kinetics400.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sathyakumarnsk/MotorServo/blob/master/demo_i3d_kinetics400.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJwhiVj8Ps7n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PW5Ad6_bP0Y8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 557
        },
        "outputId": "65aad8f8-f425-4da4-9aa7-d4e9a3927f40"
      },
      "source": [
        "pip install --upgrade mxnet gluoncv"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting mxnet\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/81/f5/d79b5b40735086ff1100c680703e0f3efc830fa455e268e9e96f3c857e93/mxnet-1.6.0-py2.py3-none-any.whl (68.7MB)\n",
            "\u001b[K     |████████████████████████████████| 68.7MB 53kB/s \n",
            "\u001b[?25hCollecting gluoncv\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b8/d7/74b530c461ac3eb90f6045a645a59450de1f3d616a4926e371daa021dbd8/gluoncv-0.8.0-py2.py3-none-any.whl (810kB)\n",
            "\u001b[K     |████████████████████████████████| 819kB 38.2MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: requests<3,>=2.20.0 in /usr/local/lib/python3.6/dist-packages (from mxnet) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy<2.0.0,>1.16.0 in /usr/local/lib/python3.6/dist-packages (from mxnet) (1.18.5)\n",
            "Collecting graphviz<0.9.0,>=0.8.1\n",
            "  Downloading https://files.pythonhosted.org/packages/53/39/4ab213673844e0c004bed8a0781a0721a3f6bb23eb8854ee75c236428892/graphviz-0.8.4-py2.py3-none-any.whl\n",
            "Collecting portalocker\n",
            "  Downloading https://files.pythonhosted.org/packages/89/a6/3814b7107e0788040870e8825eebf214d72166adf656ba7d4bf14759a06a/portalocker-2.0.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: matplotlib in /usr/local/lib/python3.6/dist-packages (from gluoncv) (3.2.2)\n",
            "Requirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.6/dist-packages (from gluoncv) (4.41.1)\n",
            "Requirement already satisfied, skipping upgrade: scipy in /usr/local/lib/python3.6/dist-packages (from gluoncv) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: Pillow in /usr/local/lib/python3.6/dist-packages (from gluoncv) (7.0.0)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet) (2020.6.20)\n",
            "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->gluoncv) (1.2.0)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->gluoncv) (2.4.7)\n",
            "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->gluoncv) (0.10.0)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->gluoncv) (2.8.1)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from cycler>=0.10->matplotlib->gluoncv) (1.15.0)\n",
            "Installing collected packages: graphviz, mxnet, portalocker, gluoncv\n",
            "  Found existing installation: graphviz 0.10.1\n",
            "    Uninstalling graphviz-0.10.1:\n",
            "      Successfully uninstalled graphviz-0.10.1\n",
            "Successfully installed gluoncv-0.8.0 graphviz-0.8.4 mxnet-1.6.0 portalocker-2.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I5S8mJ72Ps7r",
        "colab_type": "text"
      },
      "source": [
        "3. Getting Started with Pre-trained I3D Models on Kinetcis400\n",
        "================================================================\n",
        "\n",
        "`Kinetics400 <https://deepmind.com/research/open-source/kinetics>`_  is an action recognition dataset\n",
        "of realistic action videos, collected from YouTube. With 306,245 short trimmed videos\n",
        "from 400 action categories, it is one of the largest and most widely used dataset in the research\n",
        "community for benchmarking state-of-the-art video action recognition models.\n",
        "\n",
        "`I3D <https://arxiv.org/abs/1705.07750>`_ (Inflated 3D Networks) is a widely adopted 3D video\n",
        "classification network. It uses 3D convolution to learn spatiotemporal information directly from videos.\n",
        "I3D is proposed to improve `C3D <https://arxiv.org/abs/1412.0767>`_ (Convolutional 3D Networks) by inflating from 2D models.\n",
        "We can not only reuse the 2D models' architecture (e.g., ResNet, Inception), but also bootstrap\n",
        "the model weights from 2D pretrained models. In this manner, training 3D networks for video\n",
        "classification is feasible and getting much better results.\n",
        "\n",
        "In this tutorial, we will demonstrate how to load a pre-trained I3D model from `gluoncv-model-zoo`\n",
        "and classify a video clip from the Internet or your local disk into one of the 400 action classes.\n",
        "\n",
        "Step by Step\n",
        "------------\n",
        "\n",
        "We will try out a pre-trained I3D model on a single video clip.\n",
        "\n",
        "First, please follow the `installation guide <../../index.html#installation>`__\n",
        "to install ``MXNet`` and ``GluonCV`` if you haven't done so yet.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Nx0UCtkPs7r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import mxnet as mx\n",
        "from mxnet import gluon, nd, image\n",
        "from mxnet.gluon.data.vision import transforms\n",
        "from gluoncv.data.transforms import video\n",
        "from gluoncv import utils\n",
        "from gluoncv.model_zoo import get_model"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y3aU7SDOQn7x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "ae5c0d3c-4909-40b6-9765-2a9a03554bc9"
      },
      "source": [
        "pip install decord --upgrade"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting decord\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8b/2f/8578948cfdb9662a718ffb817291fc135084006f9558569a5af05fec3908/decord-0.4.0-py2.py3-none-manylinux1_x86_64.whl (11.8MB)\n",
            "\u001b[K     |████████████████████████████████| 11.8MB 335kB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: numpy>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from decord) (1.18.5)\n",
            "Installing collected packages: decord\n",
            "Successfully installed decord-0.4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H7vrAZ52Ps7t",
        "colab_type": "text"
      },
      "source": [
        "Then, we download the video and extract a 32-frame clip from it.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ur-VsnvLPs7u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "cb8cad6f-4253-4487-82b1-21308d9dfd9c"
      },
      "source": [
        "from gluoncv.utils.filesystem import try_import_decord\n",
        "decord = try_import_decord()\n",
        "\n",
        "url = 'https://github.com/bryanyzhu/tiny-ucf101/raw/master/abseiling_k400.mp4'\n",
        "video_fname = utils.download(url)\n",
        "vr = decord.VideoReader(video_fname)\n",
        "frame_id_list = range(0, 64, 2)\n",
        "video_data = vr.get_batch(frame_id_list).asnumpy()\n",
        "clip_input = [video_data[vid, :, :, :] for vid, _ in enumerate(frame_id_list)]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading abseiling_k400.mp4 from https://github.com/bryanyzhu/tiny-ucf101/raw/master/abseiling_k400.mp4...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 782/782 [00:00<00:00, 6826.39KB/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0dG_kwWAPs7x",
        "colab_type": "text"
      },
      "source": [
        "Now we define transformations for the video clip.\n",
        "This transformation function does three things:\n",
        "center crop the image to 224x224 in size,\n",
        "transpose it to ``num_channels*num_frames*height*width``,\n",
        "and normalize with mean and standard deviation calculated across all ImageNet images.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ga-qf-IPs7y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "29236a1f-d8f2-4d9d-c470-56faac085d2d"
      },
      "source": [
        "transform_fn = video.VideoGroupValTransform(size=224, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "clip_input = transform_fn(clip_input)\n",
        "clip_input = np.stack(clip_input, axis=0)\n",
        "clip_input = clip_input.reshape((-1,) + (32, 3, 224, 224))\n",
        "clip_input = np.transpose(clip_input, (0, 2, 1, 3, 4))\n",
        "print('Video data is downloaded and preprocessed.')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Video data is downloaded and preprocessed.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TI9fZ2IMPs70",
        "colab_type": "text"
      },
      "source": [
        "Next, we load a pre-trained I3D model.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dPwYIRUQPs70",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "aa074230-3c8e-4c0e-c62e-ccb587821f39"
      },
      "source": [
        "model_name = 'i3d_inceptionv1_kinetics400'\n",
        "net = get_model(model_name, nclass=400, pretrained=True)\n",
        "print('%s model is successfully loaded.' % model_name)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading /root/.mxnet/models/i3d_inceptionv1_kinetics400-81e0be10.zip from https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/models/i3d_inceptionv1_kinetics400-81e0be10.zip...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "51278KB [00:01, 33778.45KB/s]                           \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "i3d_inceptionv1_kinetics400 model is successfully loaded.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W6rYRxtlPs73",
        "colab_type": "text"
      },
      "source": [
        "Note that if you want to use InceptionV3 series model (i.e., i3d_inceptionv3_kinetics400),\n",
        "please resize the image to have both dimensions larger than 299 (e.g., 340x450) and change input size from 224 to 299\n",
        "in the transform function. Finally, we prepare the video clip and feed it to the model.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HGr7aCb9Ps73",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "6b6e73a0-4401-4771-c13f-2602df188ffd"
      },
      "source": [
        "pred = net(nd.array(clip_input))\n",
        "\n",
        "classes = net.classes\n",
        "topK = 5\n",
        "ind = nd.topk(pred, k=topK)[0].astype('int')\n",
        "print('The input video clip is classified to be')\n",
        "for i in range(topK):\n",
        "    print('\\t[%s], with probability %.3f.'%\n",
        "          (classes[ind[i].asscalar()], nd.softmax(pred)[0][ind[i]].asscalar()))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The input video clip is classified to be\n",
            "\t[abseiling], with probability 0.991.\n",
            "\t[rock_climbing], with probability 0.009.\n",
            "\t[ice_climbing], with probability 0.000.\n",
            "\t[paragliding], with probability 0.000.\n",
            "\t[skydiving], with probability 0.000.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYtYDnG7RQmc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LHLeGIezPs76",
        "colab_type": "text"
      },
      "source": [
        "We can see that our pre-trained model predicts this video clip\n",
        "to be ``abseiling`` action with high confidence.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_CG1qpqAPs76",
        "colab_type": "text"
      },
      "source": [
        "Next Step\n",
        "---------\n",
        "\n",
        "If you would like to dive deeper into training I3D models on ``Kinetics400``,\n",
        "feel free to read the next `tutorial on Kinetics400 <dive_deep_i3d_kinetics400.html>`__.\n",
        "\n"
      ]
    }
  ]
}